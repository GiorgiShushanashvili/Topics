Task and Parallel programming
Task გამოიყენება ასინქრონული ოპერაციების დროს როგორც იგივე სრიდზე ოპერაციებისას ისე ახალ სრედზე გატანისასაც,
ასინქრონული ოპერციების დროს ვერ და არც ვსასზღვრავთ თუ რომელ სრედზე წარიმართება პროცესი(უმეტესწილად ესს UI) ჩვენ უბრალოდ 
ვაკეთებთ SCHedule კონრეტულ ოპერციაზე და ის განხორციელდება ისე რომ არ დაბლოკავს ამ მთავარს სრედს.
Parallel Programming-ს აქვს დამხამრე პროპერთიები რათა გაადვილდეს ამ ლაიბრების გამოყენება, Parallel.invoke, Parallel.for,
Parallel.foreach 
პარალელური პროგრამირების დროს გამოიყენება ყველა არსებული სრედი (CPU Core) რათა ოპერაცია მაქსიმალურად სწრაფად შესრულდეს,პარალელური
ოპერიციის კარგი მაგალითია როცა გვინდა რამდენიმე განსხვავებული ელემნტის პოვნა სიმრავლეში, ასეთ დროს იდეალურია პარალელური პროგრამირების
 გამოყენება, ამას აქვს თავისი უარყოფითი მხარეებიც, სხვა იუზერებს ეზღუდებათ გამოყენების შესაძლებლობა სანამ არსებული იუზერის დაასრულებს,
 მაგრამ შეიძლება აქედანაც გამოსავლის პოვნა,task parallel libraby შეიცავს კონფიგურაციის ოპციას paralleloptions(cancellation,
maxDegreeParalleils,taskscheduler) maxdegreeparalleleism აწესებს ლიმიტს არსებული სრედების გამოყენებაზე კონკრეტულად ერთ გაშვებაზე,
 ასევე ის რომ იბლოკება მთავარი სრედი იმ შემთხვევაში თუ მასზეც მიმდინარეობს ოპერაციები,აქედან გამოსავალია
ასინქრონული პროგრამირების ინტერგრაცია პარალელური პროგრამირებასთან, რის შედეგადაც ცალკე გავიტანთ არსებულ პარალელურ ოპერაციას და გავათავისუფლებთ
მთავარ სრედს,თუმცა აქ მეორე მხარეცაა შედეგად დამატებით ერთ სრედს ვიკავებთ რაც პერფორმანსზე ახდენს გავლენას(სხვა იუზერებისთვსი ნელდება პროცესი
,მათ უწევთ მეტად დალოდება,იმ შემთხვეევაში თუ არ გვაქვს სხვა შეზღუდვა სრედებზე), შედეგად გვიწევს არჩევანის გაკეთება სისწრაფესა და მეინ სრიდის
 დაბლოკვას შორის,თუმცა დაბლოკვა ყველაზე არარელევანტური გამოსავალია. პარალელური ოპერაციების დროს გამოიყენება ConcurrentBag, პარალელური 
ოპერაციების შედეგების შესანახად რადგან პარალელური ოპერაციები სხვადასხვა სრიდებზე მიმდინარეობს  ეს არის thread-safe collection.
პარალელური ოპერციების დროს კონკრეტულ ოპერციაში არსებული ექსეფშენები იკარგება და ის ბრუნდება როგორც საერთოდ ექსეფშენი მთლიანი ოპერაციის.
რაც შეეხება პარალელური ოპერაციებს რომლებიც ჯერ არააგაშვებული ანუ maxdegreeparalleleism =2 და დანარჩენი ოპერაციების რომლებიც ელოდება განხორციელებას
,სრიდების გათავისუფლებას, თუ იმ საწყის ორ ოპერაციაზე ამოაგდებს ექსეფშენს შემდეგი ოპერაციები მაინც განხორციელდება და სულ ბოლოს როდესაც დამთავრდება 
ოპერციები მაშინ გამოიტანს ექსეფშენს. 
parallel.foreach and parallel.for აქვს გარკვეული უპირატესოსბები parallel.invoke თან შედარებით, თუ დაგვჭირდება რაიმე ოპერაციის დამატება 
parallel.invoke ით იგივე ფუნქცია უნდა გავწეროთ თავიდან ყველაზე ჯერზე რამდენჯერაც დაემატება ახალი ელემენტი,foreach and for გვაძლევას საჭირო
მოქნილობას. parallel.foreach (stocks,(element)=>{var result = Calculate(element.value);  bag(concurrentbag).add(result)});
გვაქვს BREAK and Stop ოფციები, რათა გავაკონტროლლოთ ვთქვათ რამდენ ელემენტზე გვინდა ეს ოპერაციები რომ შესრულდეს:if(x==50){state.break}
parallel.foreach ასევე for შედეგი არის parallelloopResult რომელიც შეიძლება იყოს completed და incompleted, თუ ყველა ელემენტზე გამხორციელდა
ოპერაცია მხოლოდ ამ შემთხვევაში იქნება completed.
Handling Shared Variables Usage იმ შემღხვევაში როცა ვიყენებთ shared variables in paralell.for მაგალიტად ჯამისთვის, ასეთ დროს უნდა
 გამოვიყენოთ lock method, რომელიც საშუალებას გვაძლევს რომ მხოლოდ ერთი სრედი შევიდეს მან განახორციელოს შეკების ოპერაცია,წინაშემთხვევაში შედეგი
არასწორი და განსხვავებული იქნება ყველა ჯერზე,რადგან რამდენიმე სრედტნა უწევს შეხება საბოლოო შედეგს, ამის აღმოსაფხვრელად უნდა გამოვიყენოთ lock.
lock(syncRoot) {total+=Compute(I);}  ეს არ იქნება რელევანტური იმიტომ რომ დრო უფრო მეტია ვიდრე სტანდარტული for ის დროს იმიტომ რომ compute(i)
შედარებით მძიმე ოპერაციაა და მეტ დროს მოითხოვს ამიტომ უნდა ვეცადოთ რომ lock ის შიგნით სადაც მხოლოდ ერთი სრიდი შედის მაქსიმალურად მსუბუქი
ოპერაცია შევიტანოთ, შედეგად ზემოაღნისნულს ასეთი ფორმა ექნება: for(0,100(i)=>{var result = Compute(i); lock(syncroot) {total+=result;});
შემოვიტანეთ დროებითი ცვლადი, მძიმე ოპერაციას ვაკეთებთ ცალკე და შედარებთ მსუბუქი ოპერაცია lock ის შიგნით ხდება რაც საგნობლად ამცირებს დროს.
   არსებობს lock ის ბევრად სწრაფი და ნაკლებკოდიანი ალტერნატივა interlocked რომელიც ნაკლები კოდის საშუალებით იძლევა ატომური ოპერაციის განხორციელების 
საშუალებას. lock და interlock ორივე ატომურო ოპერაციების განხორციელების მექნიზმებია,ოპერციების რომლის დროსაც მხოლოდ ერთი სრედი ახორციელებს
მოზმედებას shared Value, რაც გვაძლევს ამ ველიუზე მრავალი სრედიდად ერთდორული მოქმედების პრევენციის საშუალებას. რამდენადაც interlocked უფრო სწრაფი
და შემოკლებულია, იმდენად lock უფრო ფართო და მოქნილია.int result = 0;
Parallel.For(0, 100, (i) => {
    Interlocked.Increment(ref result);
    });
Console.WriteLine(result);
Console.ReadLine();
result გამოიტანს 100, იმიტომ რომ ყველა შემდეგი გაშვება ცალკე სრედზე წავა და წინა სრედის შედეგთან საერთო არ ექნება, შედეგი კი შესაბამისად ბოლოს გაშვებული ოპერცია
იქნება.
Deadlocks with Nested locks
დედლოქი შეიძლება მოხდეს როცა ორი სრედის მუშაობა ერთმანეთზეა დამოკიდებული და ერთ-ერთი მათგანი გაიჭედება, ამ შემთხვევაში დედლოქი შეიძლება მოხდეს
იმის გამო რომ გვაქვს ორი მეთოდი სადაც lock1 უნდა შესრულდეს ჯერ მასშივე ჩაშენებულია lock2, მეორე მეთოდში პირიქით,ანუ პირველ მეთოდში lock1-ის მუშაობა
დამოკიდებულია lock2 ის შერულებაზე და მეორე მეთოდში პირიქით, შედეგად არცერთი მათგანი არ შესრულდება საბოლოოდ.
Cancel Parallel Operations 
აქაც იგივე პრინციპია რაც task ის შემთხვევაში, ვაკეტებთ CANCELLATIONtOKENSORCE ცვლადს ინიციალიაზციას, აქ ორი ვარიანტია თუ უფრო მარალ საფეხურზე დავაყენებთ
ამ ტოკენს და მივცემთ პირობას რომ ვთქვათ 2 წამში გაითიშოს, ასეც მოხდება მაგრამ თუ გვინდა რომ უფრო სიღმეში ჩავიდეთ და ვაკონტროლოთ მთლიანად ეს მოქმედება თუ სად
და რა მომენტში გაჩერდეს მაშინ უშუალოდ მეთოდში უნდა შევაინჯექტოთ ვთქვათ INTerlock -ში. ეს მეთოდი მიზანშეწონილია გამოვიყენოთ უფრო როდესაც გვაქვს
ერთზე მეტი შედარებით მძიმე ოპერაცია და დაქენსელება მოხდება უშუალოდ ამ მეთოდებს შორის.მოქმედების პრინციპს რაც შეეხება მს შემდეგ რაც cancellationToken ამოქმედდება
რაც მნამდე დაწყებული ოპერციებია ისინი დასრულდება თუმცა ახლის დაწყება აღარ მოხდება.
ThreadLocal and AsyncLocal Variable
threadlocal ცვლადი არის ისეთი ცვალდი რომელიც რომერლიმე ერთი კონრეტული სრედის გაშვებისას არსებობს და აქვს შენახული მონაცემები, სხვა სრედებისთვის
კი მიუწვდომელია.თუმცა სრედები შეიძლება გამოყენებულ იქნეს ერთზე მეტჯერაც, ანუ რაიმე კონრეტული ოპერაციის დროს პირობითად მე-8გაშვებამ იგივე სრედ მიაკითხოს სადაც
პირველი ოპერცია განხორციელდა და შედეგად ის ცვლადი რომელიც 1-პირველ ოპერაციაში გამოვიყენეთ და შევქმენით მე-8ოპერაციაზე გვექნება და მასზე მოხდება გადაწერა
ანუ ეს ცვლადი ლოკალური აღარ უქნება რაც იყო ჩვენი მთავარი მიზანი.განსხვავებით threadllocal-ისგან Asynclocal-ის მუშაობა დამოკიდებულია task-ზე
რომელიც არაა ხელმეორედ გამოყენებადი ანუ ყოველ ოპერციას თავისი კონკრეტული task ემსახურება,რაც იმას ნიშნავს რომ სრედების შემთხვევაში არსებული საფრთხე Asynclocal
ცვლადს არ ემუქრება.მაგრამ asynclocal-ზე იქმნება local copy და თუ იქამდე ამ ლოკალურ ცვლადზე მინიჭებული გვაქვს რაიმე მნიშვნელობა, ასინქრონული მეთოდის შემდეგომ
მასზე გადაწერა არ მოხდება და მეთოდს გარეთ იგივე მნიშვნელობა ექნება რაც საწყის ეტაპზე მიენიჭა.
PLINQ - Parallel Linq
parallel ლინქი გამოიყენება პარალელურ ოპერაციებთან სამუშაოდ, კერძოდ ვთქვათ გვაქს სიმრავლე რომელიც უნდა გადავიყვანოთ პარალელური ოპერციების შესაბამის სიმრავლეში
და ისე განვახორციელოთ მასზე მოქმედებები,ასევე შესაძლებელია ერთ ლინქში ჯერ გნვახორციელოთ ოპერაციები ჯერ სტანდარტულ სიმრავლეზე და ასევე პარალელურ
სიმრავლეზეც.თუმცა ზოგჯერ საერთოდ არაა მიზანშეწონილი plinq-ის გამოყენება,რადგანაც როგორც ვიცით ისედაც overhead ხდება პარალელური ოპერციებისას და მისი
არასწორი გამოყენება ბევრად ცუდ შედგებს გვაძლევს და ასევე იმაზე მეტად ნელი შეიძლება გახდეს ოპერაცია ვიდრე სინქრონული პროცესებისას შეიძლება იყოს.
ამიტომაც გვაქვს იმის ოპცია რომ გადავიყვანოთ პარალელურში და სისტემა თვიტონ განსაზღვრავს რომელი მეთოდით უმჯობესია პარალელურით თუ სტანდარტულით
და იმ გზით განახორციელებს,ეს ძირითადად 2 მიზეზის გამოა:ესაა ერთი სისწრაფე და მეორე უსაფრთხოება.ასევე გვაქვს იმის ოპციაც რომ თუ დარწმუნებულები ვართ
რომ პარალელური უფრო უკეთესია forcparallelism ანუ ცალსახად პარალელური გავხადოთ მაგრამ უმჯობესია და საუკეთესო პრაქტიკა მაინც პირველი მათგანია,მივანდოთ სისტემას.

